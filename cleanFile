import re
import os

def remove_social_media_urls(text):
    social_media_domains = [
        'facebook.com', 'twitter.com', 'instagram.com', 'linkedin.com',
        'tiktok.com', 'youtube.com', 'pinterest.com', 'snapchat.com',
        'discord.com', 'reddit.com'
    ]
    pattern = r'https?://(?:www\.)?(?:' + '|'.join(re.escape(domain) for domain in social_media_domains) + r')[^\s]*'
    cleaned_text = re.sub(pattern, '', text)
    return cleaned_text

if __name__ == "__main__":
    input_path = "linkTextFile/external_links_from_research.txt"
    output_path = "linkTextFile/cleaned_external_links.txt"

    # Read the original text
    with open(input_path, "r", encoding="utf-8") as infile:
        raw_text = infile.read()

    # Clean the text
    cleaned = remove_social_media_urls(raw_text)

    # Save the cleaned text in the same folder with a new name
    with open(output_path, "w", encoding="utf-8") as outfile:
        outfile.write(cleaned.strip())

    print("âœ… Cleaned file saved as:", output_path)
